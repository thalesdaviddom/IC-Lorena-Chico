{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMN8cUSevM6pIdewv6/+4o4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thalesdaviddom/IC-Lorena-Chico/blob/main/Network_analisys_polisci.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "\n",
        "In this notebook we hope to perform a preliminary network analisys of our data and create the two auxiliary networks we are aiming to explore with text mining techniques. The data for this network was obtained through OpenAlex and for that reason each one of its nodes is identified by an OpenAlex_id, we would like to point out that from our original dataset of 5049 articles 5338 of them were catalogued in OpenAlex, meaning we can have a good network representation of how the articles in our dataset related to each other."
      ],
      "metadata": {
        "id": "C_P8iCwqKRQy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we will import our data and network along with the libraries used to manipulate them:"
      ],
      "metadata": {
        "id": "YBHMM6GUMCqY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4sfOhZ1pMVMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "\n",
        "#Load the CSV file\n",
        "df = pd.read_csv('/content/drive/MyDrive/Material_IC/Corpus/Artigos/dataset de trabalho/dataset.csv')\n",
        "\n",
        "# Load the GraphML file\n",
        "file_path = \"/content/drive/MyDrive/Material_IC/Corpus/Artigos/networks/citation_subnetwork.graphml\"  # Replace with your file path\n",
        "G = nx.read_graphml(file_path)"
      ],
      "metadata": {
        "id": "7tKGSArvMXH9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}